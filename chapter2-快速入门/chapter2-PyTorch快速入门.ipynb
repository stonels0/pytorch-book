{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 PyTorch第一步\n",
    "\n",
    "PyTorch的简洁设计使得它入门很简单，在深入介绍PyTorch之前，本节将先介绍一些PyTorch的基础知识，使得读者能够对PyTorch有一个大致的了解，并能够用PyTorch搭建一个简单的神经网络。部分内容读者可能暂时不太理解，可先不予以深究，本书的第3章和第4章将会对此进行深入讲解。\n",
    "\n",
    "本节内容参考了PyTorch官方教程[^1]并做了相应的增删修改，使得内容更贴合新版本的PyTorch接口，同时也更适合新手快速入门。另外本书需要读者先掌握基础的Numpy使用，其他相关知识推荐读者参考CS231n的教程[^2]。\n",
    "\n",
    "[^1]: http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "[^2]: http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "\n",
    "Tensor是PyTorch中重要的数据结构，可认为是一个「高维数组」。它可以是一个数（标量）、一维数组（向量）、二维数组（矩阵）以及更高维的数组。Tensor和Numpy的ndarrays类似，但Tensor可以**使用GPU进行加速**。Tensor的使用和Numpy及Matlab的接口十分相似，下面通过几个例子来看看Tensor的基本使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 构建 5x3 矩阵，只是分配了空间，未初始化\n",
    "x = t.Tensor(5, 3)  \n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9094, 0.0841, 0.1527],\n",
       "        [0.7387, 0.8319, 0.9492],\n",
       "        [0.3260, 0.2703, 0.7625],\n",
       "        [0.3572, 0.8509, 0.3421],\n",
       "        [0.9637, 0.7739, 0.7085]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用[0,1]均匀分布随机初始化二维数组\n",
    "x = t.rand(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "<class 'torch.Size'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.size()) # 查看x的形状，数据类型为torch.Size类型的数据结构\n",
    "print(type(x.size()))\n",
    "x.size()[1], x.size(1) # 查看列的个数, 两种写法等价 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Size` 是tuple对象的子类，因此它支持tuple的所有操作，如x.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0432, 0.3739, 1.0432],\n",
       "        [1.5281, 1.4625, 1.2640],\n",
       "        [1.2047, 0.6155, 1.0201],\n",
       "        [1.1200, 1.0266, 0.7491],\n",
       "        [1.4485, 1.3572, 1.5538]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = t.rand(5, 3)\n",
    "# 加法的第一种写法，直接采用数字加得形式进行处理「重载运算符」，原始数据未发生改变\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0432, 0.3739, 1.0432],\n",
       "        [1.5281, 1.4625, 1.2640],\n",
       "        [1.2047, 0.6155, 1.0201],\n",
       "        [1.1200, 1.0266, 0.7491],\n",
       "        [1.4485, 1.3572, 1.5538]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法的第二种写法，以类函数的形式进行调用\n",
    "t.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0432, 0.3739, 1.0432],\n",
       "        [1.5281, 1.4625, 1.2640],\n",
       "        [1.2047, 0.6155, 1.0201],\n",
       "        [1.1200, 1.0266, 0.7491],\n",
       "        [1.4485, 1.3572, 1.5538]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法的第三种写法：指定加法结果的输出目标为result，函数重载或者为参数默认值\n",
    "result = t.Tensor(5, 3) # 预先分配空间\n",
    "t.add(x, y, out=result) # 输入到result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最初y\n",
      "tensor([[0.1338, 0.2898, 0.8904],\n",
      "        [0.7895, 0.6307, 0.3148],\n",
      "        [0.8787, 0.3451, 0.2576],\n",
      "        [0.7628, 0.1756, 0.4070],\n",
      "        [0.4848, 0.5833, 0.8453]])\n",
      "第一种加法，y的结果\n",
      "tensor([[0.1338, 0.2898, 0.8904],\n",
      "        [0.7895, 0.6307, 0.3148],\n",
      "        [0.8787, 0.3451, 0.2576],\n",
      "        [0.7628, 0.1756, 0.4070],\n",
      "        [0.4848, 0.5833, 0.8453]])\n",
      "第二种加法，y的结果\n",
      "tensor([[1.0432, 0.3739, 1.0432],\n",
      "        [1.5281, 1.4625, 1.2640],\n",
      "        [1.2047, 0.6155, 1.0201],\n",
      "        [1.1200, 1.0266, 0.7491],\n",
      "        [1.4485, 1.3572, 1.5538]])\n"
     ]
    }
   ],
   "source": [
    "print('最初y')\n",
    "print(y)\n",
    "\n",
    "print('第一种加法，y的结果')\n",
    "y.add(x) # 普通加法，不改变y的内容\n",
    "print(y)\n",
    "\n",
    "print('第二种加法，y的结果')\n",
    "y.add_(x) # inplace 加法，y变了：因为采用了内部的加，注意下划线，此时y发生了改变\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，「**`inplace操作`**」函数名后面带下划线t.add**`_`** 的函数会修改Tensor本身。例如，`x.add_(y)`和`x.t_()`会改变 `x`，但`x.add(y)`和`x.t()`返回一个新的Tensor， 而`x`不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9094, 0.0841, 0.1527],\n",
      "        [0.7387, 0.8319, 0.9492],\n",
      "        [0.3260, 0.2703, 0.7625],\n",
      "        [0.3572, 0.8509, 0.3421],\n",
      "        [0.9637, 0.7739, 0.7085]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0841, 0.8319, 0.2703, 0.8509, 0.7739])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "# Tensor的选取操作与Numpy类似\n",
    "x[:, 1] # 选取x 行：所有；列：第一列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor还支持很多操作，包括数学运算、线性代数、选择、切片等等，其接口设计与**Numpy**极为相似。更详细的使用方法，会在第三章系统讲解。\n",
    "\n",
    "**相互转化：**Tensor和Numpy的数组之间的`互操作`非常容易且快速。对于Tensor不支持的操作，可以先转为Numpy数组处理，之后再转回Tensor。\n",
    "\n",
    "**注意：**Tensor和Numpy对象共享内存，相互转化十分快速；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.ones(5) # 新建一个全1的Tensor\n",
    "print(type(a))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy() # Tensor -> Numpy，调用torch成员函数「numpy」，返回numpy对象:numpy.ndarray\n",
    "print(type(b))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = t.from_numpy(a) # Numpy-> Tensor : 使用torch成员函数「from_numpy」转化numpy.ndarray对象为torch对象\n",
    "print(a)\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor和numpy对象**共享内存**，所以他们之间的转换很快，而且几乎不会消耗什么资源。但这也意味着，如果其中一个变了，另外一个也会随之改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a type is : <class 'numpy.ndarray'>, b type is : <class 'torch.Tensor'>\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print('a type is : {}, b type is : {}'.format(type(a),type(b)))\n",
    "b.add_(1) # 以`_`结尾的函数会修改自身\n",
    "print(a)\n",
    "print(b) # Tensor和Numpy共享内存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor可通过`.cuda` 方法转为**GPU的Tensor**，从而享受GPU带来的加速运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# 判断机器是否支持CUDA操作，换言之是否存在显卡及驱动\n",
    "print(t.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[1.9527, 0.4580, 1.1959],\n",
      "        [2.2668, 2.2944, 2.2132],\n",
      "        [1.5307, 0.8858, 1.7827],\n",
      "        [1.4772, 1.8775, 1.0912],\n",
      "        [2.4121, 2.1312, 2.2623]], device='cuda:0')\n",
      "cuda has acculmulate\n"
     ]
    }
   ],
   "source": [
    "# 在不支持CUDA的机器下，下一步不会运行\n",
    "if t.cuda.is_available():\n",
    "    x = x.cuda() # x转化为GPU的Tensor\n",
    "    y = y.cuda()\n",
    "    print(type(x))\n",
    "    print(x + y)\n",
    "    print('cuda has acculmulate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处可能发现GPU运算的速度并未提升太多，这是因为x和y太小且运算也较为简单，而且将数据从**内存**转移到**显存**还需要花费额外的开销。GPU的优势需在大规模数据和复杂运算下才能体现出来。\n",
    "\n",
    "### Autograd: 自动微分\n",
    "\n",
    "深度学习的算法**本质**上是通过反向传播求导数，而PyTorch的**`Autograd`**模块则实现了此功能。在Tensor上的所有操作，Autograd都能为它们自动提供微分，避免了手动计算导数的复杂过程。\n",
    " \n",
    "`autograd.Variable`是Autograd中的核心类，它简单**封装了Tensor**，并支持几乎所有Tensor有的操作。Tensor在被封装为Variable之后，可以调用它的`.backward`实现反向传播，自动计算所有梯度。Variable的数据结构如图2-6所示。\n",
    "\n",
    "\n",
    "![图2-6:Variable的数据结构](imgs/autograd_Variable.svg)\n",
    "\n",
    "\n",
    "Variable主要包含三个属性。\n",
    "- **`data`**：保存Variable所包含的Tensor\n",
    "- **`grad`**：保存`data`对应的**梯度**，`grad`也是个Variable，而不是Tensor，它和`data`的形状一样。\n",
    "- **`grad_fn`**：指向一个`Function`对象，这个`Function`用来反向传播计算输入的梯度，具体细节会在下一章讲解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "Variable data convert to numpy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用Tensor新建一个Variable\n",
    "x = Variable(t.ones(2, 2), requires_grad = True)\n",
    "print(type(x))\n",
    "y = x.data.numpy()\n",
    "print(x)\n",
    "print('Variable data convert to numpy: '.format(y))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<SumBackward0 object at 0x7ffbd4288e80>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum() # x 为torch.Variable变量，此函数含义为，设置y对象的grad_fn为 「sum」函数\n",
    "print(type(y))\n",
    "print(y.grad_fn)\n",
    "y           # y等于：tensor(4., grad_fn=<SumBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SumBackward0 at 0x7ffbd42297f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn # 此值的赋值为： y = x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward() # 函数调用：反向传播,计算梯度  调用Variable变量y的.backward实现反向传播，自动计算所有梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 如上所述：Variable变量中的：\n",
    "# data：存储数据\n",
    "# grad_fn: 存储应用在自变量的函数，用于后面计算梯度 「存储在因变量中的此属性中」\n",
    "# grad：则存储计算出的梯度值\n",
    "print(x.grad_fn,x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = x.sum() = (x[0][0] + x[0][1] + x[1][0] + x[1][1])\n",
    "# 每个值的梯度都为1\n",
    "x.grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：`grad`在反向传播过程中是**累加**的(accumulated)，这意味着每一次运行反向传播，梯度都会累加之前的梯度，所以反向传播之前需把梯度清零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以下划线结束的函数是inplace操作，就像add_\n",
    "x.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable和Tensor具有近乎一致的接口，在实际使用中可以**无缝切换**。不需要进行转化即可进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
      "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
      "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
      "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
       "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
       "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
       "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(t.ones(4,5))  # Variable 变量构建中， 构造函数传入参数为 torch.Tensor变量\n",
    "y = t.cos(x)\n",
    "x_tensor_cos = t.cos(x.data)\n",
    "print(y)\n",
    "x_tensor_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  神经网络\n",
    "\n",
    "Autograd实现了反向传播功能，但是直接用来写深度学习的代码在很多情况下还是稍显复杂，**`torch.nn`**是专门为神经网络设计的模块化接口。nn构建于 Autograd之上，可用来定义和运行神经网络。**nn.Module**是nn中最重要的类，可把它看成是一个网络的封装，包含网络各层定义以及forward方法，调用forward(input)方法，可返回前向传播的结果。下面就以最早的卷积神经网络：LeNet为例，来看看如何用`nn.Module`实现。LeNet的网络结构如图2-7所示。\n",
    "\n",
    "![图2-7:LeNet网络结构](imgs/nn_lenet.png)\n",
    "\n",
    "这是一个基础的前向传播(feed-forward)网络: 接收输入，经过层层传递运算，得到输出。\n",
    "\n",
    "#### 定义网络\n",
    "\n",
    "1. 继承 nn.Module 模块；\n",
    "2. 实现对应forward方法；\n",
    "3. 将具有可学习参数的层，放置到`__init__`构造函数中；\n",
    "4. 不具有可学习参数的层，则在forward中使用 `nn.functional`代替；\n",
    "5. 网络的可学习参数通过`net.parameters()`返回，`net.named_parameters`可同时返回可学习的参数及名称(net为定义网络的实例）。\n",
    "\n",
    "\n",
    "定义网络时，需要**继承**`nn.Module`，并**实现**它的forward方法，把网络中**具有可学习参数的层**放在构造函数`__init__`中。如果某一层(如ReLU)不具有可学习的参数，则既可以放在构造函数中，也可以不放，但建议不放在其中，而在forward中使用`nn.functional`代替。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # 不具有 「可学习参数」的层，如池化层、激活函数，则在 「forward函数中」使用 nn.functional替代\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # nn.Module子类的函数必须在构造函数中执行父类的构造函数\n",
    "        # 下式等价于 nn.Module.__init__(self) :调用nn.Module的构造函数\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 卷积层  '1' 表示输入图片为单通道， '6' 表示输出通道数， '5' 表示卷积核 为 5*5\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        # 卷积层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # 仿射层/ 全连接层 ， y = Wx+b\n",
    "        self.fc1 = nn.Linear(16*5*5, 120) # 输入为 16*5*5 = 400， 输出为 120\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # pdb.set_trace()\n",
    "        # 卷积 -> 激活 -> 池化 # 假设输入为 [1, 1, 32, 32], 感受野计算公式 ： (图像size - 卷积核size + 2 * padding)/ stride + 1\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))  # (14 * 14) * 6\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)       # (5* 5) * 16\n",
    "        # reshape, '-1':表示自适应\n",
    "        x = x.view(x.size()[0], -1)  # 全卷积层 需要将图像进行拉伸为 一列;\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只要在**nn.Module的子类**中定义了forward函数，backward函数就会**自动被实现**(利用`Autograd`)。在`forward` 函数中可使用任何Variable支持的函数，还可以使用if、for循环、print、log等Python语法，写法和标准的Python写法一致。\n",
    "\n",
    "网络的可学习参数通过`net.parameters()`返回，`net.named_parameters`可同时返回可学习的参数及名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7ffbd4285390>\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "params = net.parameters()\n",
    "print(params)\n",
    "params = list(net.parameters())\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 1, 5, 5])\n",
      "conv1.bias : torch.Size([6])\n",
      "conv2.weight : torch.Size([16, 6, 5, 5])\n",
      "conv2.bias : torch.Size([16])\n",
      "fc1.weight : torch.Size([120, 400])\n",
      "fc1.bias : torch.Size([120])\n",
      "fc2.weight : torch.Size([84, 120])\n",
      "fc2.bias : torch.Size([84])\n",
      "fc3.weight : torch.Size([10, 84])\n",
      "fc3.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name,parameters in net.named_parameters():\n",
    "    print(name,':',parameters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 1, 5, 5])\n",
      "conv1.bias : torch.Size([6])\n",
      "conv2.weight : torch.Size([16, 6, 5, 5])\n",
      "conv2.bias : torch.Size([16])\n",
      "fc1.weight : torch.Size([120, 400])\n",
      "fc1.bias : torch.Size([120])\n",
      "fc2.weight : torch.Size([84, 120])\n",
      "fc2.bias : torch.Size([84])\n",
      "fc3.weight : torch.Size([10, 84])\n",
      "fc3.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name,parameters in net.named_parameters():\n",
    "    print(name,':',parameters.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward函数的输入和输出都是Variable，只有Variable才具有自动求导功能，而Tensor是没有的，所以在输入时，需把Tensor封装成Variable。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor和Variable的合并\n",
    "说是合并, 其实是按照以前(0.1-0.3版本)的观点是:**Tensor现在默认requires_grad=False的Variable了**. torch.Tensor和torch.autograd.Variable现在其实是同一个类! 没有本质的区别! \n",
    "\n",
    "换言之，现在已经没有纯粹的Tensor了, 是个Tensor, 它就支持自动求导! \n",
    "\n",
    "#### 注意：\n",
    "- 此前,Variable.data 属性：为了拿到Variable对象中的tensor。后期版本中，因为两者合并，所以「**`.data`**」返回一个**新的 requires_grad = True 的Tensor，且这个tensor于之前那个Tensor共享内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1.post2\n"
     ]
    }
   ],
   "source": [
    "# 打印当前pytorch的版本\n",
    "print(t.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 查看Tensor的类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.DoubleTensor\n",
      "False\n",
      "torch.FloatTensor\n",
      "False\n",
      "the tensor requires is :  True\n",
      "the tensor z is :  False\n",
      "the sum tensor grad is :  True\n"
     ]
    }
   ],
   "source": [
    "# 使用.isinstance()或是x.type(), 用type()不能看tensor的具体类型\n",
    "x = t.DoubleTensor([1, 1, 1])\n",
    "print(type(x)) # 不能查看tensor的具体类型\n",
    "# 查看具体类型\n",
    "print(x.type()) # 调用torch.Tensor对象的成员函数\n",
    "print(isinstance(x, t.FloatTensor)) # 查看是否为torch.FloatTensor类型\n",
    "x = t.rand(2,3)\n",
    "print(x.type()) # was torch.FloatTensor\n",
    "# tensor 和 Variable的合并，requires_grad 已经成为Tensor的一个属性；\n",
    "print(x.requires_grad)  # 默认为false\n",
    "\n",
    "# 将 `requires_grad` 作为一个参数，构造tensor\n",
    "w = t.ones(1, requires_grad = True)\n",
    "z = t.ones(1)\n",
    "print('the tensor requires is : ', w.requires_grad)\n",
    "print('the tensor z is : ', z.requires_grad)\n",
    "total = t.add(z,w)\n",
    "print('the sum tensor grad is : ',total.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size is :  torch.Size([1, 1, 32, 32])\n",
      "input type is :  torch.FloatTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "input = t.randn(1,1,32, 32, dtype=torch.float32) # nn.Conv2d 输入必须是4维的，形如 nSamples×nChannels×Height×Width \n",
    "print ('input size is : ', input.size())\n",
    "print('input type is : ', input.type()) # was torch.FloatTensor\n",
    "output = net(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad() # 所有参数的梯度清零\n",
    "output.backward(t.ones(1,10)) # 反向传播\n",
    "# out.backward(Variable(t.ones(1,10))) # 反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，torch.nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。但如果只想输入一个样本，则用 `input.unsqueeze(0)`将batch_size设为１。例如 `nn.Conv2d` 输入必须是4维的，形如$nSamples \\times nChannels \\times Height \\times Width$。可将nSample设为1，即$1 \\times nChannels \\times Height \\times Width$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 损失函数\n",
    "\n",
    "nn实现了神经网络中大多数的损失函数，例如nn.MSELoss用来计算均方误差，nn.CrossEntropyLoss用来计算交叉熵损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targe is :  torch.FloatTensor\n",
      "output is :  torch.FloatTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(28.5087, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = t.arange(0, 10, dtype = t.float32)\n",
    "target = target.view(-1, output.size()[1])\n",
    "print('targe is : ', target.type())\n",
    "print('output is : ', output.type())\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果对loss进行反向传播溯源(使用`gradfn`属性)，可看到它的计算图如下：\n",
    "\n",
    "```\n",
    "input -> (conv2d -> relu -> maxpool2d) -> (conv2d -> relu -> maxpool2d)  \n",
    "      -> view -> (linear -> relu) -> (linear -> relu) -> (linear) \n",
    "      -> MSELoss\n",
    "      -> loss\n",
    "```\n",
    "\n",
    "当调用`loss.backward()`时，该图会动态生成并自动微分，也即会自动计算图中参数(Parameter)的导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反向传播之前 conv1.bias的梯度\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "反向传播之后 conv1.bias的梯度\n",
      "tensor([-0.0490,  0.0829,  0.0852, -0.0242, -0.0952,  0.0121])\n"
     ]
    }
   ],
   "source": [
    "# 运行.backward，观察调用之前和调用之后的grad\n",
    "net.zero_grad() # 把net中所有可学习参数的梯度清零\n",
    "print('反向传播之前 conv1.bias的梯度')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('反向传播之后 conv1.bias的梯度')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在反向传播计算完所有参数的梯度后，还需要使用优化方法来更新网络的权重和参数，例如随机梯度下降法(SGD)的更新策略如下：\n",
    "```\n",
    "weight = weight - learning_rate * gradient\n",
    "```\n",
    "\n",
    "手动实现如下：\n",
    "\n",
    "```python\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)# inplace 减法\n",
    "```\n",
    "\n",
    "`torch.optim`中实现了深度学习中绝大多数的优化方法，例如RMSProp、Adam、SGD等，更便于使用，因此大多数时候并不需要手动写上述代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#新建一个优化器，指定要调整的参数和学习率\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "# 在训练过程中\n",
    "# 先梯度清零(与net.zero_grad()效果一样)\n",
    "optimizer.zero_grad() \n",
    "\n",
    "# 计算损失\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "#反向传播\n",
    "loss.backward()\n",
    "\n",
    "#更新参数\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "####  数据加载与预处理\n",
    "\n",
    "在深度学习中数据加载及预处理是非常复杂繁琐的，但PyTorch提供了一些可极大简化和加快数据处理流程的工具。同时，对于常用的数据集，PyTorch也提供了封装好的接口供用户快速调用，这些数据集主要保存在torchvison中。\n",
    "\n",
    "`torchvision`实现了常用的图像数据加载功能，例如Imagenet、CIFAR10、MNIST等，以及常用的数据转换操作，这极大地方便了数据加载，并且代码具有可重用性。\n",
    "\n",
    "\n",
    "### 小试牛刀：CIFAR-10分类\n",
    "\n",
    "下面我们来尝试实现对CIFAR-10数据集的分类，步骤如下: \n",
    "\n",
    "1. **数据：**使用`torchvision`**加载**并**预处理**CIFAR-10数据集\n",
    "2. **网络：**定义网络\n",
    "3. **损失函数和优化器：**定义损失函数和优化器\n",
    "4. **训练及更新：**训练网络并更新网络参数\n",
    "5. **验证：**测试网络\n",
    "\n",
    "####   CIFAR-10数据加载及预处理\n",
    "\n",
    "CIFAR-10[^3]是一个常用的彩色图片数据集，它有10个类别: 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'。每张图片都是$3\\times32\\times32$，也即3-通道彩色图片，分辨率为$32\\times32$。\n",
    "\n",
    "[^3]: http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "show = ToPILImage() # 可以把Tensor转成Image，方便可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 第一次运行程序torchvision会自动下载CIFAR-10数据集，\n",
    "# 大约100M，需花费一定的时间，\n",
    "# 如果已经下载有CIFAR-10，可通过root参数指定\n",
    "\n",
    "# 定义对数据的预处理\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(), # 转为Tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 归一化\n",
    "                             ])\n",
    "\n",
    "# 训练集\n",
    "trainset = tv.datasets.CIFAR10(\n",
    "                    root='~/Append/0_personLearn/5_tmp/data/', \n",
    "                    train=True, \n",
    "                    download=True,\n",
    "                    transform=transform)\n",
    "\n",
    "trainloader = t.utils.data.DataLoader(\n",
    "                    trainset, \n",
    "                    batch_size=4,\n",
    "                    shuffle=True, \n",
    "                    num_workers=2)\n",
    "\n",
    "# 测试集\n",
    "testset = tv.datasets.CIFAR10(\n",
    "                    root='~/Append/0_personLearn/5_tmp/data/', \n",
    "                    train=False, \n",
    "                    download=True, \n",
    "                    transform=transform)\n",
    "\n",
    "testloader = t.utils.data.DataLoader(\n",
    "                    testset,\n",
    "                    batch_size=4, \n",
    "                    shuffle=False,\n",
    "                    num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset对象(trainset、testset)**是一个数据集，可以按下标访问，返回形如(data, label)的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.cifar.CIFAR10'>\n"
     ]
    }
   ],
   "source": [
    "(data, label) = trainset[100]\n",
    "print(type(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0x7FFB71FC6748>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data, label) = trainset[100]\n",
    "print(classes[label])\n",
    "\n",
    "# (data + 1) / 2是为了还原被归一化的数据\n",
    "show((data + 1) / 2).resize((100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader是一个**可迭代的对象**，它将dataset返回的每一条数据拼接成一个batch（上述定义中，已将batch_size = 4），并提供**多线程加速优化和数据打乱**等操作。当程序对dataset的所有数据遍历完一遍之后，相应的对Dataloader也完成了一次迭代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       frog       horse         car        bird\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=400x100 at 0x7FFB7603F588>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next() # 返回4张图片及标签\n",
    "print(' '.join('%11s'%classes[labels[j]] for j in range(4)))\n",
    "show(tv.utils.make_grid((images+1)/2)).resize((400,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   定义网络\n",
    "\n",
    "拷贝上面的LeNet网络，修改self.conv1第一个参数为3通道，因CIFAR-10是3通道彩图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  \n",
    "        self.fc1   = nn.Linear(16*5*5, 120)  \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  定义损失函数和优化器(loss和optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   训练网络\n",
    "\n",
    "所有网络的训练流程都是类似的，不断地执行如下流程：\n",
    "\n",
    "- 输入数据\n",
    "- 前向传播+反向传播\n",
    "- 更新参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a99bf9e0b034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_num_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "t.set_num_threads(8)\n",
    "for epoch in range(2):  \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 输入数据\n",
    "        inputs, labels = data\n",
    "        # inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()   \n",
    "        \n",
    "        # 更新参数 \n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印log信息\n",
    "        #running_loss += loss.data[0]\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999: # 每2000个batch打印一下训练状态\n",
    "            print('[%d, %5d] loss: %.3f' \\\n",
    "                  % (epoch+1, i+1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处仅训练了2个epoch（**遍历完一遍数据集**称为一个epoch），来看看网络有没有效果。将测试图片输入到网络中，计算它的label，然后与实际的label进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实际的label:       cat     ship     ship    plane\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAABkCAIAAAAnqfEgAAA0bklEQVR4nO19WZMc6XXdqcysvbq6em/0ABgAg2UwxAyHo5mhRIkSJdohWrbssOWwFXaEIxzhFz/4wb9DP8ARDlNW2H6wZYclh+RNFmmSokmKnN2zYkCgATS6G71UV1fXmpWLH/KcW9Xd1SNRCke45e8+ALezsjK//PKrzHvuci7gxIkTJ06cOHHixIkTJ06cOHHixIkTJ06cOHHixImT/78kd3rTb/3TV/RZkimFIACQ87zszzAcZkqUjLhDoZApccKvpEnKg3hxpujbSKOqjh8DyBcG2Z8+An0l1dGiTBlFPGyS2IADjYFbhlJy3DPR0XIaNkcbRzqRLtADBxnqWx2eGb2QH/3Gv7uPCdnf3+cAIu6ay02ZzJ9UfrKDpCeV8QYv+5MbvNQ7uUdO8yMlhU0gd05T2/tPGKTtuby8fOKj3/rWOrWYE7W/u50pw8EAwLXnrmd/NmbrmZL3OYBC3qdiW7SMgpwWSdTPlFo1r6/nAAQ+B+l7PMjBQTNTZmZmuGc+r6NxH1stURJmiq1b/pnj371uj98NuJxKpVKmhCG/G+mXUi6VdXyeqDFTmjzs13/zn/EqFm/yKz5/U/WZWqYcDbkUu+19jU2/C93XQMMtB0UAJT/QuHUr7dZpQ5zEJ7Yk2jI+rK7R83xMWwC5nP3e7acan9qH3yoWi5lS8Io6dRFArsDJ6e1/lCk//8u/duIgHpw4ceLknEhwelNoL9iE7y4kCYAiaBl54IMwCE5aTzJZkAu4aWhvG71bgoQfZU9/7Yic7DVEQ51IT/rE19j4XooDPpvDUB9Fno4TA8jJOisV9E7WdXmBvZx1RnDnFPZa4Nsg8KY/033fn7r9zyl/NjMtp7fZ2CLycgASe5+mGm0qM0qvXDMzJ779Z7ewTkutwjvlpVxswy63JGEPQKnAo1XL3CHQ4W0BFLVKyrqbnoY9jG0fro1C3gMnAACCQGaa7DUvd/Lai4IIsuTQ7Y10IkoGI1Itfk8nyMv6MHttNBzqQjRs2RQ44/4mKQcf+XM8SJ4/t9inheXlZWH1O5mSxl2dmscZptxn5CUABpo3/VwQjghoPC3gfo8/c1vSdiEGSjyPSpqEADwzeDVvUaQVaE+AnD0lOD9zc7y0YnlGh+WNSLwUQK7I88adGs4QZ2E5ceLk3Ih7YDlx4uTcyBRImApMAcPJLTnhskQoz68Ihcm0Nh+fudwKBZp5UZLXR/7kPmZM5uSn9/QYzXk0OFOPBnM/oWm7vUcbtRPyW53OSJcUA6iVBAQ0ttkKHZ/lEi8w8eRYFXTyZfDndSFhMh3sGAj6DDT0Z5A/zdHGiMx2Hhvi9kl2IQLmI15yYOAh1i3LnT5jcmrLnyCfMewgx1Mbviv4PH7eiwEUPYF32y5/+bBPx7bv876XAt7E0VDQxuB8xC1pLgAQC+EW8vyKIUEIN1l4IZY7otfjGfd3dzNlZZFAJvPH+wWuDF/HtwnM6+0fCC0OFWewCMBoZD+uY+Kl3B5rbLGCIXGO11Wa4akXnl3htw4PMqXWI0gMB/zNxrUSgGS2kf05I9xtJ/IshjYMNQk8Y6nE2R5PmO5vtvZsBdpBIl1XYmtHS7EQcMmVy4o8wCA5pz1BDCAx++lsx4izsJw4cXJuxD2wnDhxcm5kCiQMElqVlrvhJSNMmO4TURyFbE6F0iJDUhZMUSrK6sqtTGm39gDs7dMIzwcFnU4RQCVM9VHJlA/XaaijtMB9PH4U1ggbm+0mgI2nrezPWpEHSba55fIqT7RQM6BhKWC8xoIs2/hUOgn3lNX650y/+nMhSp05NnyqZLQoSQCMBLc/vc8kspVV5kkZrl+aJ+QpKUaT/ORD+oxJKCgRL4nkSRAQyHsJgLz+9GKuhEJekMSPtWcoRXczJziv5RoNFC70qwAGusCKXAG+BQ4Nt+hKuwPCrjfffCtTRkKjc/XXeNiiB0DYDjmD4VohniGd1KLbgqsWxk2mQ8IICpyBizMRQB4qwutLqSrmV6/olr31o0wJd4kNL7x4C0Bulz+KYY4xx5ou4KjPCGNJwy6mPJq3oLikooQWPB1WSgCCkeDwSEercraLh4eZElx6IVN6jVkOUpg91o0oJbzYXJoC8GLFauMzDSlnYTlx4uTciHtgOXHi5NzIFEhoSCMXNKh4OQhlAPCEm0IZ+YUCbdR4nD92MgOzoCDKF//SX86UN7/3fQCbB3vZn10BwCiiRfpwYydT7j95kimluQuZcnH1CrcUWM8RClEWassAogFt472dzUypNOYzZaPzNFMGuqKVGo3hiooD4pCI4Kwn+uko4f+l0pzPxIwKbuZVGqW80H5nCKB1SLP/6R6rUsozhAYLKk+xWhMLmVmxztTxjc/6p5OCHAipLi1vZSLxEICvMF8uJrjLK1Y7MhAhqOvXDUQo6Vc1NElkML4IoNNuZX/VKoRFnmbSKmYCBYNbCg4221TKSrkMheHCUQIgKNh9VxQv5kgi/Rysdq0gV0OqlZbE0z0M4x+dRfFSqyRT0qeAWU7YbZBTjVGscrclQv7eUQhgdP8Tjk2ek0QVQd1AF6axFSKVFj1WmnGo+i0Fjge1EgB/wD8DXjGGFzik/pbqn3JL/O7sIi9EJxp5FlflVSdpAsCX9yDwzlzzzsJy4sTJuZEpFtbQ42P7sMenchwNAczV+EiuqyInkGfd/KnjysrkZLpHr8uckW/+/n/KlKcHAwBPO9zh4SZ3WN98zOOXaGpFPs2oWp1P66BS0z58LZT08C15FQB7MpHWLl7OlIFsrvv3aWE1W8rlWePRri5TyQd6t5zhJbXKjDT5CQyOdDxBx7aPE1tOWVixJtXKuX29aa1yYne/nSntLq+oP4wBdHsqciryVnb7vFO1iswNjaQwHsyfcBU/kS1ZzFliEWcyr/rYLJdqnEiV6HbkVKPjncxj8nOqEZE5ZlNppfgxRgA6R5yTR5axJaPJjKNLdU6LZV298+57mfL5O5/LlMSSwuIQQCm1dELOZL8nnKE1E42UPhbw+CNVyA+HPUyTWJZXovy41IwJ/cpCy9XSiWaPNBvLzMwqLz/LMaSH2Zi4w+IqR5tXPfM2K6ihipyuwmLpCiNaeVXRDQSYqjNVAOERr2KoyQnK8pdrBQYLtPVyeZmiKU3FGS0fX4ZblMsDyHlKEsSZdW/OwnLixMm5EffAcuLEybmRKZBwt0d7rBk1MuXb/+vbAG7foGPvl+4Ql81ZsbWlooiSwVNFjhU9yLeLBw+ZE9TsFQGkFfrCvZqyP+aPMqWkDI5QaTKh1dnMced6jaN6urWVKe1WE0BdxnBJPtdHAoD5Ou3nna2HmVJ7yjNeqKt8x7MIgDE6HJNuz6gsZGPLtDYuMF88AaYYbZBhQy859s6wIiEDZh0hGvO+l+XKHageYkuQcOeASsbTMBLe6x0RDu/I+77xhNP1wo1rmfLclYscrdKIxv5+o9PKTfw7Ubrhne2I9+U4TwSUPDkQ+odtABBKSkUJ4Iu2oWCEazaBI4YRYsNWsT4ae/dDAN0uE4KePuWe1XpNJxI21EyGHe5TUvhot9XKlLfeJ0isFn0A169xugJB0WGPi6csFpBkyLURKw4QG9YZtDFVLKXOuKjGmYz6SLAxL5RdvPcpj/rGdzIlev2L+lYRQJoSkxYEHgfglda2eIG+mCSSqiqWUsVwRvzWzEKDp36yDwAdLqf8Ct1HeEyAGWiSB7ucN1/em+QmM7MG4njwcubvzwEItFzTs6M+zsJy4sTJuRH3wHLixMm5kWmlOY2rmdLb4+NsVFgC0BRU7IUEWfWCUmDGoTRDQ7RFBxFB1q5M+N22Ig6NBQBzy4zidRJay4sqxLEIYKh8j4Gq0vuKAT2riEZPGHAnHAAIlJbVaurEGmRfBq1f4Imethmg3GoTvzy7KGx7hnXa6jNKVauI1zAwFGxsENrbwiKGBMdEesffGaeyura3mIM2P0/sXC7x0oYDXlqlyC2rS0TrGd9xt8fLqcoIDwdia9OFdcQ2F42LjRRaGqeA2UeTVzNJDoGzpGRsedrJIGExjQHUFGadNW48pY8VhY9KBo+ExD1d+5hmNxYXdjsEMFPl9jnN24MNUjPff0zlk3t/mCmtvVamdAYcWy98P1MCKLuq1wZw5yYpjP/GX/tapjyjFTgscbSDLscfdnmieqqkpP4RpkneV1mMJsHChYkcL8ZAWTvg8aMN5hjWC/ylHG3yjGFpFkAqwsvcFlMaq89wuYZ14S9wkZQ7Sh9rcZADVU1Fe3QgFAYhgKhNuF1sMnw/6guPlwmZWw8Y6y+UCQlnLjCC6SsXLFXi1RApgEgLL0zOxITOwnLixMm5EffAcuLEybmRKZDw1ksMNGz8gHn9tdklAK9/idsr3nqmhIqPGBrKiV8tRiNTZoT43nmPEY1agyb0M1fuAEhl0hcMYA5YrNNTZYBnTTs04A/fezdTZkvcUlGQsVapAdjcpm1sBRueQOK80gVbB7R4D5pU7m/R1l1bZqJdoFGdkKDOq4iF6UaKkEJBHFMs9GPVIYaP0uMppOPooRSrIzEOAMO2DdXZjFQ9DyGLSm0GE5Aw5xv/gTqXlHXLrE+M4rjjGM2pwWSQP3/y88/ChI/X1zVIzuRRm8smHg0BPFHd1YHoIrod4v3lBaK5WpUowlfScmiUhAXx8+n+dgc9AAMbtLjkH21yXT3YYKi0F4quQ4FjVHh8IxW3aq3tR58A2BTm+qPvfDdTbt98LlOWGsRH/U6LI1F7m9FtMpR0RLl3QorCdKnuIIw0RZDZk9JRlVvn1c9nSj34KV7REed25Gcs6UZEqQhjmSfqxqK7kCtgJI6EvFZyXwz6lsfZj2MAvQ7PUtXRBtqzqJ/h/AxZQGI9HDpaclDyankk/r9cbuJCMTp7OTkLy4kTJ+dG3APLiRMn50amQMLKLMHOs9cYEMmKpZ69yoaXiyNihtZ9Jl6OBFLiiGjr9V/4m5ly+dqrmXL1xfVMefNtorm52iqAzR0a6oHYvEoKaakmHB3l9R0e0MaeU9dMsx2tFnxxcRHAQFX2e8oAtFKyWk1RSGWHhgo53X+8kSnLcwQaNy4qNe64fP1f/Rse1hJHZfrOqEfm9auEw6+99ILOyK9bcmkWiUsNv8g+jzSlFuQqFIUajABDWY4Lc8pZtQ5shQIm2AKQl+muoraWAqMtMa4dHbYyZWQ5sQrwLShv8Mb1awDyVqFm3TknQOMJ+c73fpApRtVvRZG9QQfA+vYT7UCxWZpT5nBVgdGizpNXKmmgvEdPbb56gxBAoLasqeDwVlPE5wrfVmoNnVMEJB2r9eOZrAS1XqsD+OlXX8r+7B42tQNx96NHnNJ79+7xIwXPH+5zSvsKIJ6QapXrLdKVjmK7C0RzRpeSEwour3B+2urqunvI0eZ8H0CoZmUFC8C1uGck5F9Ujndba7JkHQ2MLlE+jWFWnaq2DId9zZvwa0V1jjMXL2WKbx6GcWc53eBxPnIKjNdTcnbmqLOwnDhxcm5kioXlF+k2e7L9YaZ84dXXAFRnaZj4R8biIONCr9wfb9Ab93NzTOZChQUfM1VVPwQ8frlQwUQxhPmS19bo8P7wHot4CnJJtuVTvHqJ1t/N51lV32yqg0g9B2Bzm4knnt4SDfFhtcSUZDZXudLIlL7K0D99pPKgwvRn+kD+7LCv8nSZM51DXbq2xLef57dSI/YVL22hjAlTZUx2LFNrdp4pPGMiB+t3YvwNskmtACrhvzzausqhnuxwWpr7tFX7fdWRDPW2FKODUQtcvESf9OVLFwFUC7ZsLHRwpoX1zl2euqISDbvRg6gHoDHP3DG7y6GMmp2O5laXXCtx7UUyFT1rrarWSl5QBVDoqhvoiC78ZrN5Yth2a0MRRbR1RqsGu7zIZTM/fwETFT/7B5zJhQbP++rnuRQ3NmmntwecqI9UuXKaTJwXKD96eYYX2FHKYaBVGltClipaPC2nRMliOV+xCM/HhLN8JPKSstomGbwwW9V87bHm1nrwRCqJy5dzABKlvBnJnfE65CM1NrZMQ323FNsql+VpnNXIYeJ25M5eTs7CcuLEybkR98By4sTJuZEpkDBfordyMDBoMAKQVyFLpWquUDr/iqJbnQloQ/7WP/8XmfKrf/ef8LAqUygUzYaPAFy99kz2506TzteBHJ+rywQLRlw7VCuUa9cZAXjuOrHh4dvsd9I96gBoi/Q2iszFSyO/oXyZpEWre3ZO3Axy1fseL2RjcwfT5O/8rV/jkOSirp7qE1kWdDLO4XZbbAoigcgHJQCB8llS2ed9ZS2liXLQhCby8u4HZsznrdDnGKK0fJaBaA+MsWCu0ciUWCyAJZ/jb+0T9Ww8Wc+U64q3+F6ACdzqC6V+RmnOkSXCmatb2LDilQBcvMQ8pnDIkext8yt7TQZkVpfJBldapCu32drXUblzfY64tVScAzAQy0Yv4pyXKrrvEe/7uLerHPbm3Ih6HO3rP3UnU24+uwZgENJr/uDH/Mq9Tz7IlJ957cVMuXSZS/rRe4xKmb88OaPopKBsr4LyChPR3ZUVMInEgHjUVutTEYSUZolbV6qKEaUJjrUsFQOibBRf3oNxZOaUpCoPMkgY+ykmGBA9KQVDnzrsUOSLRtMS6NpjTfu49VQSYKJwzSgqT4uzsJw4cXJuxD2wnDhxcm5kijWYU3FAT9Bs0OsDyKu95dG+akRUiJMHQcSFBi3DTz9kKsrmBhX0iPgePl7PlC+sfhHAM88yJri2Q6V7jzvMFxqZUm8QG96//4AnWqPV3RLIGsl8fbqzDyAxqgRZvD3F9bxTDAxW1mMBrIJ4zsL9bUyTRMloYxtbH9UKrJgplzhjfdG29UacuvX7vMZCoQzg8lUWsj94zPr73/uv38iUSNGcko5WMUVAslEn2GnMEhF84QsvAVhaZHnEcxc5XV5OnIKy1C0SZGGj/jLxxdqFBpVn2Kwo45DrKbtnjILPfvHlRcy/uMwxWOB1b+8xgE5XBAYqzbBksYaYyNeu3ciU+iyvqL5IkLin6HAi7JxVofTUKLSncFsYKrNJJAQFY3kMeMsKYmpfXuWULs1RKeU9AEsCnnWlL+0/JO57+OP1TFlV3LO1/X0edp6jDc/AX4F4C3w1iC3pZ9jaYXCz2SFlwu4Wo5BzM0yZvPMC0ai1K874D0aKx1lU2parNSUwV0NuDPC5czwOR1o8L/vIvqtqm/F31VBHZ7QlZzvnlRmXt2BgCgCeEG58dlqfs7CcOHFybsQ9sJw4cXJuZJqBarUmCg1cWFzABBL55rtEeXMKAN2Yp7FXKljYhfhrd4cgLhm2MuXydVJ8+aUigEqdRv7iClNM91VC0VJw0PgBl5eZRRkIn1oJjpXvZ9FAK22xDMOBIoyRWMYXBSvgqQmryMxKinFEYhM8Ib/7e3/AsYn32lPyXk3h1BkhtSs3eGlLC8RHCxdYtTO/uAygJDaC1kfEF+9//ChT+sKvBibsvsyIrv765SuZ8qUvvsLjV2cAVH3V0MjEDjVdkdpk9awiRw1ByzpsoyG+/G02RtvbawIoq45kZZUTWKko+/eUNATnJwqhRMIHD0BT5HnttlIljfNbKO/RBgdQb/O79dkGdxYdXE/5rshFmKwvqfB2lCpWxGMAhzNZ0z6B2pdeWuC1G1tDt90CEAlgGp/9VcHVjz76cabcvPW8js/Z3lQqaUmFVifE4Jh1BkiE1I6ULL27S+/EQZNH++S9H2bKx+8Se16/ziKwK9dvA5hbFAuFQJaxSxpPv6Ev3+hGtC0Y9yI41mtuoh2sgo/a08LFpzsNm4yDj2POkuws9lOd3lsPzsJy4sTJOZJpeVh6WNZretPOlDHRUrQtsqC9Fp93i3UepypPZKQOKOvK5VmZb2TKs3oJZJkyP3zzo+zPJ1v0ns7UaHPllYHywaePNDorPVG6hx7GnS7fvXML8wAi7bCtGp1anQMI5HSv6L1qRSEImfiT9DiY1eXpxc8/evt/Z0pZNEzDkJ71vJzKP/3Tr2fKwyeki92n2xR3PscyjkK5BKA3pHWQlxn7yiukOhqoGap5iG9cY9nT58SytLbIS6tXaPskgxDA4232B905EAf0Hrd0O/RJt1QcHo7UKV4nsnJrq8EajSIAlQbn5A54FbOz02cJQHC8JhkTL8msXNnCI4FqtmxLocTDLi7R61+r8QJLCjgEGmSQ543IctBSFYJY36NZ5aB51u1JnFCB1bgMlZqnMus04rTE8RBAqNKTvi6nMsO0xIfb9I5/cJ/Wt9X3jFT2lLbPTHrKxEyVkvjBn5e9dv02oxa9I973D95i7uFbb9DC+s531jPlww/fB3Dr9svZnzdu3c6UxlwjU2w5+f5Jw0qVXZNbtACSGBNZhCZWrBPLmE/GKWBnypgVLudjooouSs7M63MWlhMnTs6NuAeWEydOzo1MY2uQg+3C8gXt5AFIlLBz4SIhyY821zOlBTVrCegmbyzSLTdbp6Fu+ThXBAlrswsA/uVv/uvsz56O3+6z6qKn8hrzN682RJXV5Km7RTsRvaQffbwJYEe0BObKbXgcZL0haCAWpCCkMR/0mAY1XxGOKE03aXcfE6XOy8a+eJEe6Bc+z2qhvGDF++/8MccvO78mkqOdvS0A1TphxUKdO/z1r/08B6kcp9lZ7rO4wOybZpMT9eAh6acPW4Sl7cMjAEeKWhyIhqmpfieRQhAFebgLgvNGYlGvc/xWxzO3PAOgaFC6LGoBUVaclnmRTSehebh5oiTqAyiIZWF5ZS1Tcqo9KiiryMBpSZUrvgZptBbG/pzlBFmiWa+rQhxjgJI/PhU27B1yJp+scyabyhFqqKvrykIDQEl0EeYYTgOi+EClP3tqZnNxjUuupmtvD6a7k61kx1oRp55tkWNbmVmNBdYn/dxXuOSuX+dP8rvf+lam3F/fANB7WywUYih58SW6Gi5d4kECRWbiyBi9rZBI12jO9DTFRD9gIxCx5k/GdTXuA2ttay29y+qTxk53D0CSnsSVp8VZWE6cODk34h5YTpw4OTcyBRIa8W59jsZ8FAcAijJ9b4r590dvEFsdFljNn4Dm98pFHvmDDxm/+Nmv/MNM+b44c7vdNoCRAnM7WydDgZ1I8SNht4ZH7PZMmdjncJc2fOQ3MmV1pYEJa9YqcgbiQe70xMWsjqrRgGVDywFDjWuiUR5GVs9xTJ7cZY1+W7GnX/3lf5wpX/vaVzPlD7/JaNGy+CGW1XW1rFSgUi4BsCI+3xkpJSVDRbLGDRZFSmPZ/oTDfrTDNKVQ7XOCUhXAzAyzfpYFZEbhyfhOXkjQSuRNmZlhkK5en9FHOQAdEfI+fcp7Z3N7WioCSpGnsJqSzhr1ZQDJmAaS96Vc4+lSq+oQbElSbTlFs5uaggRApBsXxRxbe19k3HbtgoSdQwZPN9XCZ3Ve1U5Vpv5lPZwSQdFIh7Fw5DMCWbduMtPw5Reo3L3PMPHb732EaZITEvTEZeyJ+CTvW6GMsqIUxfMUGL1xk8TNiX4ym9v/AUBzj+A0UXHY0ycfZ8pzNxg3vP05fnd5RS4g/dKjkfialcwYpzEm7ssUamzh7tMkfGOWx/HF2pdSYIwwxxU/p8RZWE6cODk34h5YTpw4OTcyBRJWa4Qtc4uMcWQ97weqXynVZC0rePToEYsGvvw62c4GHSVn1mlsb22wnuDTu3d52CjEuDEHOuJdqM8TilppTkMprLdu8fg/fIeW7Vsfr/PUX/mVTMmIBu/f+/TEQSzXdKDqisurRHMl5VvOzwuMiJIwCqfnsA16jLu9+HkWyv/SV38pUxbUKfZnv6hIn6DHjCqK6ppkv1DCRDdQi1sZS7c1CqrLUE9EDHFNs7F8kXHJ5gHncKbRADASWskJLxlvt4WlrOlLR9G0VC1SjFb88RYTXgf9HoCRUHasEo1K9czSHIPktQrn1vDdzu4+gLYyVy1f9PotJkYa3bufNzRExXBxqIYtPVHr9Yc9AJHyeD2VHCVD7lkTCjaa/3JBJV+KfzXkE5gVyXo4HALoaZBGN+ipoGROcL4iisqNxyy0EqrD556/gWlihP3+WJErwOqIrHQmORZcAxAK6V+8dCVTrly5CuANaycszsKdnRYVocWPPmIXq6tXObbnnqOyssJU1RklxyKXBzBQW9ZYv4684LyFAi1x1CpzUuOxHIutzxwmi4Qcp7sTJ07+Aoh7YDlx4uTcyBRImETEULPzREzdfgygJ3xhUaTLl0lCcPd9orzDnpIDq4wkXiZhN9Y/Wc+UzU3ii5/50msAusId9TXmDc6vMbbyqEnc11NL1UKVNvzsMo//Sp1j2N1jDGh9fQNAR7X7LbWWXF6i2V8HjeErNWK35brI0UEcESrGVD2DS+za8y9nyq//g3/EQcYEGp/cY8wuyYnEQpHEkTLimi3Vuyc9ALG6ZipGhATEL0dtFuv7T2n2byondihUkigdsaoo5P1PNwA8eKTAq1IxFxYX9F2l6aqR6p4mEEogHDMdSqlVygAaJZ7FOAX7nemxVEzkozb3OOz7YmqPkiGARoOlo2trpBYIVao2Cgknk5RDaguJ9/rG5DHUaIWh8h4mcF9J3BJl5YuaTyBRuK0qBkdDZAVV2Nlqz8KpRi6Y80/G7Eai4d/YZ+Vmr9vKFCuoXL1wEdPEF1wyBToRcgrsjtMsT9X66SOrQKzP1IHJuk0pRrGvyHu7yfvy9h7x4wfv/ihT5lX/u7rKn9vq2hUApZLynBcYWFxaoRvH0nftlkXyMFjr1nHiqOWdJh4mWBzSM5jv4SwsJ06cnCOZYmEdiVKgLA/xcBBCnS0wkZi/NM/X9V15zneafAHu6Z3cmOGj9/aLdEnef8iclIzAypziN2/Qc3zjKq2y9c1WpmSl5wD294xfQd1f9G7ceJ/m2NZ+G0BOIQJfFf+rF2m4XdFT+rJ8+cZ+NZQplyR5DXJ6LcWv/f2/xwGs8p357vuMKpgHNBy3CVG9hVy25lbM+prE9m6xHp/jVwm3hHo37u3RgrNUI7OEGmKJylzRzX01Rpe/dm9PjULFFxzJ6W7FOtY5pqK26SUlH3mRDyC0jjRqf1JWatVpaal+aGuThm1VlT3Pv/AigAWxklUU+hiI3fjggGl3xiTRE61CRXlqs3Wu0qp61pcLeQCBbKVYTvcsyANgJKLqgXV2GXP+iqVXeEKZbQj8AoBULVcHQyr7uzQY9/YZX7JqMGPCMF6QokiNT0guNQuLW8xFnZOpYtwGExUxVMzn3e/QHt/e2gKwtUWjqX2oCjkZhjMK+9RklJXEO2IUchvbXNJ319kNdzCIAUQxD7K4RFR05w7r7W7eYDLa0hJva32WkZNimU+AFFot+oHQpjfabud0d+LEyV8AcQ8sJ06cnBuZAgnv36P5d1nJ+yUvBJAIRARmQ5qHT07lmkiBn3+eqTR/+Af/JVN6LVqnlQX6Vu9t7AC4eJH+vKu3SO9bFCR57ln2kmk1W5ny4Yf07icCIxsHtPPbfdn5cRFAu0WkubxKG/VRk1vmLzYyZV+QB+qV0pK/OVVDoEEyxDR55503MuW9997JFE+GrifT2koczOcKGCMCjeqg4GFiJgtjogLx+SpFy0v5Ub1IL7UnAozIt2tX+lgKAAUhkUgsgL2WRRV0XVasIxQaynsdqW1SRzioUggALIvALxAuK5xZSoH5Zd7ueWEEYwHOFtKRCqSOOup4WsxraOLVkxv+mRVGToq6d771jlUxVnfQBzBQsKIlXGmQbTDgGW/fJjdeXhmFE3zBJ1v4DLtHADa26dDY2aWvOhSUNnIRyywryFXS0TV+4xvfwFRRMldiOVaR6mOEFq0PVM5X0pMglS83/LtvvckztnYALCiJ7PEWr72uZLG8VrgF2epKPQvEjlIITnpgOl4HwH6LgZr1ByxQax1wWt56QwtYpJiXL9MVsyZa8Atr/EmurXBLtTYHIFcW5YN3Zlqfs7CcOHFybsQ9sJw4cXJuZAokfOdTBqEu3yEleYIugJzFy2S1ttXPo9VioGRh/uVM+ZWv/WKmvPx5Wt2//R9/J1NyKvWenZ0D8Mwao2zGue5HDBLNr3J4a9eICFrCIG+/806mbHXEvZ2nrTu7ughg8Tr/9AXHYpnUd9UI59620rv03LY6la6uNUpsir6FCfmjb/+PTOmJGq2Q52HLqkGx6fVTVfZbG8u8QcIcgFLxJMouiF8hUOpZSW1lDWgodgevZC8ehV3CEMBAZTEjBcgs88heVcF4i65UkHy2RujRqHBLreIDKAT8Sl4pQrl4OnDGRGcUS9oKBHuTDOxYDYoyniz1rSTcN+hy/P1DLrm+uq8GBZtSEcXFEYBPPiRaebi+zpEI+BuSWrvANKJ5kSP2BetMOZA7otnaB9ALLf/L6EC4xXr62s2oCFttqbZpW7UyJ2QkhG4h5lwk2gZDi9o5VQqVhRQ7Cg4O+jzOrZsvAHjl5deyP994jy0I/vhHzLE6FKl/rLWxvMqQ35e//OVMCXTL1tUs9vs/+D6Az71ALv+6XEA7uq5tJQlaTHZVJBBXr17hGRUT7x4d6opSAHm1sx2c4hQxcRaWEydOzo24B5YTJ07OjUyBhHfbBCN7sagL8gMAXij7LRH/lrLs1tRQ88tfYqSvlGfc6uqzLPj+q3/71zPl3//Of86U3e1DAJuHRhvA/qwFWbzNHpV7YoOAIjLpIpHm3DJHa2AnSxlNSrZdJGRCsoeRijbGiZG0rbsezfuR4l5pMt06XVmiMbzVZ/wljluZUlezzEClOe091moctWmHj2KLfw0xtRZBHGaFMufWMG805njj+6ai1q1VkazHWVauHVb8ATkBqJJwX1mTMK8U3EtSLq4xJCcgjsHgCICndrOBMEmjXj45fsndTz7MlBfuEEfYtGej8xSaS1TDYbCiJwb6QY8RagsXWqPca6IzX15mgmJW+REoVjsr9kQ7ryXlWvLnRx9/kilGUGHOAcuizBZYR0mhfXEWGiQM1avNOOMfPeXasAzS+IwGVuO2o2P2dP5vJHlCzEgEEi2oWVY4+Mtf+ao+8TDB137zZbp3XvwpKgqujuffegVcu8bM7UAzduUGSf7WLt8CUC7zdlufARu/9Rkw3Le8xNRxo3zwhZQ9eWniZAhgpCtNctNnCc7CcuLEyTmSKRbWJ2qP+rvfpaPuC88uAlgtqHm3XiAXVvnsvLDIl9hz11TbqRKKrV0+cb/+b2lYvfU2X7lZxc9E6YucpnLXxSUeNjY3s/zl1ic18tSI/PilDELrPmJ9t2kn+LI7UtUMR7LO8lY6Y0lJ4fQqgXSkEvEq30JH1jUz5kv4+du0KZILtLl29zgbO6Lr7bRiTLylYyVSJRGPVg34Xnr+JfJQb8q5uyt/fz88+drPSn+KKq6q6pY1qpyuJTX7WV3jTbyu2uOVEqeuo8SofdXHZh7uquIAtRm+aRcW5nCGjJT0NOhwtJ6sy8yKMHos63h67y7tnSMLaOidnFdQwhrfJ1aqbWW9cQpgcYGDNHuqN7aeqDx69PjEPqZYp/ieCrAPWy0A3T21yw1s2Lwco+jqKk0pUo1RPO7tPt126PdpQvpKHwtEBh3qpxQp9zDSldphjd3MqneiOMJEM5tQ1uva5au6QhWHSfFEmvbgETPX+qGhFrFmz16dPN3BofpOaTaq9Su6UNX5H/LSNp82NVqOsqj6uayyKFdTdfrBmU2YnIXlxImTcyPugeXEiZNzI1MgYUd22jfeYh3Mp/fuA/grr7Ig+7k1gpQH90lD/POvkau3lKer+EiI7Lf/G/M+3v6Axfq9SAUxQQmAJzfwuJeknO6pZz45fjQUZBtpS07JNUMdNjM3g+AkuKtUZH/KtI4NQ2ge7ESR2mQWlB12QvY3Wcgej2i+9mXt96zHqjpfLolAKj8kZCuLYKHvpwDS1ICxsIP8jr0+weOXXyfAvHObpMyPHjE7Zu+ATn0rE8kc2oabSjrdkiBVQ8xZsc64vcejfSJeJMjnWl8mvKrM1gFUZvjdebFr1eR8PS1l3YhQiMxCHFnQxpMzuSDcak16LDJQk1PZU2ZQRRcSKWfn7sek62g39wG0VA2TWLtcHS3QkiiJ5MD4LnrC9bsi7TJI6HsBgDmth1B79pQSFokEIhkDwJO0CrncdBPh29/+nxx8RMLiipKSElE/G/nHGIQmlhopwmgLESQRAE9IbSBwl4z5sKz+RlGXBmMstZquUT147Dv00Ht2B5UEZwmGenpY0MMbE4+cuvZxUmAMAFUdRIGs0+IsLCdOnJwbcQ8sJ06cnBuZAgkXFmkZNptEJVutAwDfU6OaePSs9qXVtyQSO/i02H/4Bin3fv+b38uUYVLVOcVq4B17XMaWYyVD0ZqhGieslddYjCZnBSXGkeD5mMj1mDH227H5OjpxtEQkCmZar64S49TrVN7AMVlV4G/jEbFhNLTsGCoPFO06VJ6UXXBX6V3daAQgiQ0SiodaIGI4IOJ467v/PVN+scoruqMr6os+wUJmWR3VwCJcAhE7exztQxEW7/UY9hoIHpUEAOeVXlea5fj9cgEChgCKwpU5f8pC4iVrkAZGPNVmZaMd6AItx6pkeTpSLMAXNulYeGw0x8ZZbKHeoICJkqygZEfjkELh/Y4oPSxuaB1hLTZc0vhH/RDASIwCFpC1AJ/5NCxzKlKiYhob7J0edC5phURCgoFqwoLCrEaiuKQ5T8b83epVYyCRa83CiOHx7ZOXaI2UbA9ROap3VDhQ6dXx32ykJrgGzC030NNoPZzEjyZhx259BGCgz0vBHs4QZ2E5ceLk3Ih7YDlx4uTcyBRLPpAdmy+IQmxQBPBgx+okmPn5C6+Qpa/cYEF2W5zov/HHhFAD2agjGfxFMXtlJrTlTJr4MiZPW8/F00jQdlYtTrlUxkQmm5GyH6nhipVHDAVSZhus6li9QKUmHNETI8UJuXyTJGTtLiFVd8PsWHG/Ceg1daKCqmpChQXjjLHbYLAdIrW4Erfce4/x1sdHnMklT+1XlS4Yy+rueAmA7ZRo5Z6ikxtiBegZAcNl1uivXiGbWkm1LDCgJ8q9Wq0GoKIonqfE1PSM4BeAtpg8ekoc3dkUB8MgBBArRdYoJUaCbHZd1kI0L6KIcRRYit3xbMKMm2HQURxZRAtHh1QsNludUVKxJjAdKTAtFsMsr/VQ3YYMCcbKyTRi+OTU3TSCitwYsh0TyxPudBjwrcjFYceyTsAWCgwjG5syLT2LG0YAQmPpEPeDJZ2Ow4WG2cdI08alORT+zb5lZXATFWXxCcUaqXqnfsf2USAgORpFAHpzXFcXLs7gDHEWlhMnTs6NuAeWEydOzo1MbaRqPT5lKwYlAGFEu3ynQ/vzzY8ZsvmVHm28o5QAarNJpaQgXdSzHDYRhFcqAAIZq1Yfn9OoLKxgMcFUHAbGhGfFZZ2Qww6jLgQMMVH+bgCwO6ChWxMSnFtmPZ2RiH/8gCHRfGK27jGpNxhKW1phKG1LkNAsYKvMH8pOtp5RsXo3xTgJH04M2w43Egbp7jGtzis2MsUX68CmTvQOhgDuCUB1apy32kUW/S2qbe2irr2o5MwxF5+gTVEM9H7gA/CtyaiF87TltGw//FQHO1kBl0XTAjG4Ww/OnHUzzRMWVUSOmDuFXyIVhHYiRRKHEYBElXFjAjz1+yoUGYlbfoaT0BVcbR9QsaZn6TgKmcMEgZ+xOKTpyTtl2DBvRAu6y73edA/DxiPSDX66zfNWldQaCEVG45XFGYv1UaKgc36chj2CKgoB6NLHLgZrEGtd+8YxR9tH99dmO2OkSOKT8VBPvo6cGErG5PRaRafmCR3l9MZzFQDPvMQmEnUlFJwWZ2E5ceLk3Mi09JkxZY96cnh5AIn1mJSZs77D18XXf5utcb76lVcz5f4mrYDeONdJvnxVV/iFAoCK3pkF2Up9FVWYvzyVcZQv8dS+3vnmoLUt2aO9b3k6uhzboSHjaGGVsYLdPdaRt1SV0npEu+D6NVW3H5eSOtYUdTn2covlr5XfHFHu5JSOi/azneztY/vpLZdK6egt95Fe8rNqqPPxgKzW74tdulmvAJi/xMGvXSErWWON116ocPzWhHWksQWya3wpgd722Rt1bCLl7AV75pvPT5SmFJu7VzZLdjRL2EntLc3vDsW8HIkbI9GcTvAfUMzpnnUVNesgkKkVaxWViqpYUu3RwR7tmq5iLHmtdt+6ew6HmOhhYybweBK0kq3jaUlLriPaiV73ENPEg1aRLYTYiKRlAdkk+5pJGVDWHtWKsbI5tilNlftmk5sadDCCCuvBI/7uWJ+NzJTz8wBS61Rk5F1mnVnb1/H8KI6h8EgkMuu6mEIuvngTQJDj7WjdfR9niLOwnDhxcm7EPbCcOHFybmQKJJxXU0mrmehGIYCCOi9aKoenRK3v/PC9TFnfpBv+sEcbuykPvTJCUBUYySoMijqI4Y6S/OW+zHL7yGzUSEAvZ749mbhxOMJEBkpZSHNxntQC80tEgqHAwlB1/H1j7xWgyLpynhYrlO+qWH+mwRMNugQyxv0QyyqOxwa/xm8W9HFJhX1SJUN1lWLzXXFVPxKF9H5FuUgrzA5bvbgE4NoiowoLCi94mvyuAKDVQwTywtaMOVo7B0qdK5UrAIqa0rzIOT5DzNU9ZgFW+lOa5ACkikSMkaa+ay722Nz8QqnFohwLWiTG+pDy4OZv1u1Q1CJU+lhP6UXd4zUiAHIFHnagPMFs/FoyY0xvkNC2GBtEGvLUB/vE7KPwjOVkpJXaYSSsbh9BxTqWg5gIf3maWyPqS9IIkzBcnpmCrt3wZZIeQ+iYyMMajeSrNy97mmKiFe6YhcI8C6nc/7mTP9WRqC7nbpKC+eJVlvQNnu4A+LH4NsoipDwtzsJy4sTJuRH3wHLixMm5kSmQcCgQpE4rGCYjAHlxM0RmFRv/gUJm65vkALA6+yg0y9a646hZaa+DidiKlexUraFLhdjQk8FZMP42oRWrvN9tijEaESZKN+aU1LG60KCyykhZS9it3WI9REfdTRrqfLO3M71wPFQxhF+gxTu3xBON1H80UrhwZJE4494WJMyuzDJ3cqeCg1BVRyDeu1FZpS2zHORzsysaNqtqavUAwIygYlGVRgOr6rB4pdHaiT9vjBY0hrwgeRZpzWtPS8hKz6AqBzAIrfTfIlbH0nw8XaCRu9uSmIB7wiCWPWSwKzm5wLJamZHSCX2t55FwX6zDVrUUDQl6RpLRV7HL8T43yal4riVkBQLINi3Np/w5jIaM3uZOQn+JBQBF5+ApXphXTA3x+IfHnRV5H5M2mIshzQEoCdg26mK4twvRsM25YT+Zgm732Pmj72WRRPtK58hi8Tqs7mbbgs6LPPXlmzczZX6eDoqNj9goa//efUxknJUKZ02Ts7CcOHFyfsQ9sJw4cXJuZCokpDFcFAbJCvsTxS9yFqSwou2xchIJpslJ0z0dl3onmLD/Dw6I6ZpiSa/XWJAxK4BW92hMJurtGSVDXYkgQMkHMBTlmDGIB7KWo566MPW4T6fF7luJyAyM7XsQTH+mB0oTbSwQnNbESB0PxWomKGgNoNIxmZlRC3iYQCLWm9aI0AJBzrKyEOs1VZbUSO1WE1NFTbA6s+pDcfJ1NNqeAQHjNRcrQEGIzACgAbEx/kpTAKGK7AsFKUo1PC35ovE1KnPYPAmehwmmh3FwcJxmezKwCEUSLQJrlWSRQloZsX1fSDDuq5hGUcKqvlKeZeDY+OdGKtvyToE3onWL/I4bnlKrCq522/QwtJUvaojZ7jtUlcLt5mcx8nWVSKXim/RVkWOKDXLM22d1NrkUE5yIvaCtAYxBob4rX42mJQjtbnqnvnVMIo3Nzmvp5fVlFYHduqZj8UQf//AHmTLc4e/Oj2NMVAslZ7SbhbOwnDhx4sSJEydOnDhx4sSJEydOnDhx4sSJEydOnDhx4sSJEyf/z8r/Ab+8NWulkQjIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=400x100 at 0x7FFB76035128>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next() # 一个batch返回4张图片\n",
    "print('实际的label: ', ' '.join(\\\n",
    "            '%08s'%classes[labels[j]] for j in range(4)))\n",
    "show(tv.utils.make_grid(images / 2 - 0.5)).resize((400,100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着计算网络预测的label："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算图片在每个类别上的分数\n",
    "outputs = net(Variable(images))\n",
    "# 得分最高的那个类\n",
    "# _, predicted = t.max(outputs.data, 1)\n",
    "import pdb\n",
    "pdb.set_trace()\n",
    "_, predicted = t.max(outputs, 1)\n",
    "\n",
    "print('预测结果: ', ' '.join('%5s'\\\n",
    "            % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已经可以看出效果，准确率50%，但这只是一部分的图片，再来看看在整个测试集上的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(images)\n",
    "    _, predicted = t.max(output, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0 # 预测正确的图片数\n",
    "total = 0 # 总共的图片数\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = t.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的准确率远比随机猜测(准确率10%)好，证明网络确实学到了东西。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  在GPU训练\n",
    "就像之前把Tensor从CPU转到GPU一样，模型也可以类似地从CPU转到GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if t.cuda.is_available():\n",
    "    net.cuda()\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    output = net(Variable(images))\n",
    "    loss= criterion(output,Variable(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果发现在GPU上并没有比CPU提速很多，实际上是因为网络比较小，GPU没有完全发挥自己的真正实力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对PyTorch的基础介绍至此结束。总结一下，本节主要包含以下内容。\n",
    "\n",
    "1. Tensor: 类似Numpy数组的数据结构，与Numpy接口类似，可方便地互相转换。\n",
    "2. autograd/Variable: Variable封装了Tensor，并提供自动求导功能。\n",
    "3. nn: 专门为神经网络设计的接口，提供了很多有用的功能(神经网络层，损失函数，优化器等)。\n",
    "4. 神经网络训练: 以CIFAR-10分类为例演示了神经网络的训练流程，包括数据加载、网络搭建、训练及测试。\n",
    "\n",
    "通过本节的学习，相信读者可以体会出PyTorch具有接口简单、使用灵活等特点。从下一章开始，本书将深入系统地讲解PyTorch的各部分知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pytorch 0.4.1.post2版本CIFAR-10 代码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "[1,  2000] loss: 2.205\n",
      "[1,  4000] loss: 1.895\n",
      "[1,  6000] loss: 1.697\n",
      "[1,  8000] loss: 1.598\n",
      "[1, 10000] loss: 1.540\n",
      "[1, 12000] loss: 1.493\n",
      "[2,  2000] loss: 1.437\n",
      "[2,  4000] loss: 1.397\n",
      "[2,  6000] loss: 1.375\n",
      "[2,  8000] loss: 1.343\n",
      "[2, 10000] loss: 1.288\n",
      "[2, 12000] loss: 1.306\n",
      "[3,  2000] loss: 1.218\n",
      "[3,  4000] loss: 1.230\n",
      "[3,  6000] loss: 1.240\n",
      "[3,  8000] loss: 1.233\n",
      "[3, 10000] loss: 1.178\n",
      "[3, 12000] loss: 1.202\n",
      "[4,  2000] loss: 1.125\n",
      "[4,  4000] loss: 1.123\n",
      "[4,  6000] loss: 1.124\n",
      "[4,  8000] loss: 1.140\n",
      "[4, 10000] loss: 1.110\n",
      "[4, 12000] loss: 1.137\n",
      "[5,  2000] loss: 0.999\n",
      "[5,  4000] loss: 1.058\n",
      "[5,  6000] loss: 1.081\n",
      "[5,  8000] loss: 1.054\n",
      "[5, 10000] loss: 1.046\n",
      "[5, 12000] loss: 1.057\n",
      "[6,  2000] loss: 0.945\n",
      "[6,  4000] loss: 0.989\n",
      "[6,  6000] loss: 0.989\n",
      "[6,  8000] loss: 0.999\n",
      "[6, 10000] loss: 1.005\n",
      "[6, 12000] loss: 1.021\n",
      "[7,  2000] loss: 0.915\n",
      "[7,  4000] loss: 0.929\n",
      "[7,  6000] loss: 0.935\n",
      "[7,  8000] loss: 0.976\n",
      "[7, 10000] loss: 0.953\n",
      "[7, 12000] loss: 0.962\n",
      "[8,  2000] loss: 0.850\n",
      "[8,  4000] loss: 0.885\n",
      "[8,  6000] loss: 0.894\n",
      "[8,  8000] loss: 0.930\n",
      "[8, 10000] loss: 0.914\n",
      "[8, 12000] loss: 0.930\n",
      "[9,  2000] loss: 0.832\n",
      "[9,  4000] loss: 0.850\n",
      "[9,  6000] loss: 0.867\n",
      "[9,  8000] loss: 0.877\n",
      "[9, 10000] loss: 0.870\n",
      "[9, 12000] loss: 0.918\n",
      "[10,  2000] loss: 0.787\n",
      "[10,  4000] loss: 0.806\n",
      "[10,  6000] loss: 0.840\n",
      "[10,  8000] loss: 0.873\n",
      "[10, 10000] loss: 0.840\n",
      "[10, 12000] loss: 0.867\n",
      "[11,  2000] loss: 0.764\n",
      "[11,  4000] loss: 0.796\n",
      "[11,  6000] loss: 0.801\n",
      "[11,  8000] loss: 0.817\n",
      "[11, 10000] loss: 0.830\n",
      "[11, 12000] loss: 0.836\n",
      "[12,  2000] loss: 0.740\n",
      "[12,  4000] loss: 0.731\n",
      "[12,  6000] loss: 0.766\n",
      "[12,  8000] loss: 0.815\n",
      "[12, 10000] loss: 0.820\n",
      "[12, 12000] loss: 0.810\n",
      "[13,  2000] loss: 0.689\n",
      "[13,  4000] loss: 0.738\n",
      "[13,  6000] loss: 0.777\n",
      "[13,  8000] loss: 0.783\n",
      "[13, 10000] loss: 0.790\n",
      "[13, 12000] loss: 0.801\n",
      "[14,  2000] loss: 0.698\n",
      "[14,  4000] loss: 0.709\n",
      "[14,  6000] loss: 0.738\n",
      "[14,  8000] loss: 0.756\n",
      "[14, 10000] loss: 0.761\n",
      "[14, 12000] loss: 0.781\n",
      "[15,  2000] loss: 0.653\n",
      "[15,  4000] loss: 0.696\n",
      "[15,  6000] loss: 0.729\n",
      "[15,  8000] loss: 0.733\n",
      "[15, 10000] loss: 0.749\n",
      "[15, 12000] loss: 0.770\n",
      "Finished Training\n",
      "10000张测试集中的准确率为: 62 %\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Author: Lishi\n",
    "# @Date:   2018-06-17 09:51:56\n",
    "# @Last Modified by:   zhanglishi001\n",
    "# @Last Modified time: 2018-06-26 12:09:24\n",
    "\n",
    "import torch as t\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "show = ToPILImage() # 可以把Tensor转成Image，方便可视化\n",
    "import pdb\n",
    "\n",
    "# torch.device object used throughout this script\n",
    "use_cuda = torch.cuda.is_available() \n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"LeNet网络，修改 self.conv1第一个参数为3通道\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  \n",
    "        self.fc1   = nn.Linear(16*5*5, 120)  \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 第一次运行程序torchvision会自动下载CIFAR-10数据集\n",
    "    # 大约100M，需花费一定的时间，\n",
    "    # 如果已经下载有CIFAR-10，可通过root参数指定\n",
    "\n",
    "    # 定义对数据的预处理\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(), # 转为Tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 归一化\n",
    "                             ])\n",
    "    # 训练集\n",
    "    trainset = tv.datasets.CIFAR10(\n",
    "                    root='~/Append/0_personLearn/5_tmp/data/', \n",
    "                    train=True, \n",
    "                    download=True,\n",
    "                    transform=transform)\n",
    "\n",
    "    trainloader = t.utils.data.DataLoader(\n",
    "                    trainset, \n",
    "                    batch_size=4,\n",
    "                    shuffle=True, \n",
    "                    num_workers=2)\n",
    "\n",
    "    # 测试集\n",
    "    testset = tv.datasets.CIFAR10(\n",
    "                    root='~/Append/0_personLearn/5_tmp/data/', \n",
    "                    train=False, \n",
    "                    download=True, \n",
    "                    transform=transform)\n",
    "\n",
    "    testloader = t.utils.data.DataLoader(\n",
    "                    testset,\n",
    "                    batch_size=4, \n",
    "                    shuffle=False,\n",
    "                    num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    net = Net().to(device)\n",
    "    print(net)\n",
    "\n",
    "    # 定义损失函数和优化器(loss和optimizer)\n",
    "    from torch import optim\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum=0.9)\n",
    "\n",
    "    thread_nums = 8\n",
    "    epoch_nums = 15\n",
    "    t.set_num_threads(8)\n",
    "    for epoch in range(epoch_nums):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # 输入数据\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "\n",
    "            # 打印log信息\n",
    "            #running_loss += loss.data[0]\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999: # 每2000个batch打印一下训练状态\n",
    "                print('[%d, %5d] loss: %.3f' \\\n",
    "                      % (epoch+1, i+1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = t.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch = 10:10000张测试集中的准确率为: 63 %\n",
    "\n",
    "epoch = 15:10000张测试集中的准确率为: 62 %\n",
    "\n",
    "epoch = 20:10000张测试集中的准确率为: 61 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
